import os
import glob
import base64
import time
import uuid
import json
import torch
import whisper
# from whisper.utils import get_writer
import subprocess
from datetime import timedelta
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from tqdm import tqdm
from openai import OpenAI
# å¯¼å…¥å¤„ç†å›¾ç‰‡ç›¸ä¼¼åº¦çš„å‡½æ•°ï¼
from app.actions.generate_ppt import generate_ppt
# ä¸ºäº†å¤šå‡½æ•°åŒæ—¶è¿è¡Œå®ç°çš„
import threading
from concurrent.futures import ThreadPoolExecutor  # æ›´ç®€æ´çš„çº¿ç¨‹æ± API
import re  # å¯¼å…¥æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—
from dotenv import load_dotenv
load_dotenv()  # åŠ è½½ç¯å¢ƒå˜é‡
# åˆå§‹åŒ–Flaskåº”ç”¨
app = Flask(__name__)
CORS(app)  # è§£å†³è·¨åŸŸé—®é¢˜

# é…ç½® - ä½¿ç”¨ç»å¯¹è·¯å¾„é¿å…ç›¸å¯¹è·¯å¾„é—®é¢˜
BASE_DIR = os.path.abspath(os.path.dirname(__file__))
UPLOAD_FOLDER = os.path.join(BASE_DIR, 'uploads')
FRAMES_FOLDER = os.path.join(BASE_DIR, 'frames')
AUDIO_FOLDER = os.path.join(BASE_DIR, 'audio')
OUTPUT_FOLDER = os.path.join(BASE_DIR, 'outputs')
ALLOWED_EXTENSIONS = {'mp4', 'mov', 'avi', 'mkv', 'flv'}

# åˆ›å»ºå¿…è¦çš„æ–‡ä»¶å¤¹
for folder in [UPLOAD_FOLDER, FRAMES_FOLDER, AUDIO_FOLDER, OUTPUT_FOLDER]:
    if not os.path.exists(folder):
        os.makedirs(folder, exist_ok=True)

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['FRAMES_FOLDER'] = FRAMES_FOLDER
app.config['AUDIO_FOLDER'] = AUDIO_FOLDER
app.config['OUTPUT_FOLDER'] = OUTPUT_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 100 * 1024 * 1024  # é™åˆ¶ä¸Šä¼ æ–‡ä»¶å¤§å°ä¸º100MB


# é˜¿é‡Œäº‘åƒé—®æ¨¡å‹é…ç½®
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")
if not DASHSCOPE_API_KEY:
    app.logger.error("æœªæ‰¾åˆ° DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·å…ˆé…ç½®")
    raise EnvironmentError("DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡æœªé…ç½®")

# åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼ˆå…¼å®¹é˜¿é‡Œäº‘åƒé—®ï¼‰
client = OpenAI(
    api_key=DASHSCOPE_API_KEY,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)


def allowed_file(filename):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºå…è®¸çš„è§†é¢‘æ ¼å¼"""
    return '.' in filename and \
        filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


def get_video_duration(video_path):
    """è·å–è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰"""
    try:
        result = subprocess.run(
            ["ffmpeg", "-i", video_path, "-vstats", "-"],
            capture_output=True,
            text=True,
        encoding = 'utf-8'  # æ˜¾å¼æŒ‡å®šç¼–ç ä¸º UTF-8
        )

        for line in result.stderr.split('\n'):
            if 'Duration' in line:
                duration_str = line.split(',')[0].split('Duration: ')[1].strip()
                h, m, s = duration_str.split(':')
                return int(h) * 3600 + int(m) * 60 + float(s)
        return 0
    except Exception as e:
        app.logger.error(f"è·å–è§†é¢‘æ—¶é•¿å¤±è´¥: {str(e)}")
        return 0


def extract_audio_from_video(video_path, video_id):
    """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘ï¼ˆç”¨äºè¯­éŸ³è¯†åˆ«ï¼‰"""
    app.logger.info("å¼€å§‹ä»è§†é¢‘ä¸­æå–éŸ³é¢‘...")

    audio_dir = os.path.join(app.config['AUDIO_FOLDER'], video_id)
    os.makedirs(audio_dir, exist_ok=True)
    audio_path = os.path.join(audio_dir, "audio.wav")

    # ä½¿ç”¨ffmpegæå–16000Hzå•å£°é“WAVéŸ³é¢‘ï¼ˆç™¾åº¦AIæ¨èæ ¼å¼ï¼‰
    cmd = [
        'ffmpeg', '-i', video_path, '-vn', '-acodec', 'pcm_s16le',
        '-ar', '16000', '-ac', '1', '-y',  # -yè‡ªåŠ¨è¦†ç›–æ–‡ä»¶
        audio_path
    ]

    try:
        subprocess.run(cmd, check=True, capture_output=True, text=True,
    encoding='utf-8'  # æ˜¾å¼æŒ‡å®šç¼–ç ä¸º UTF-8
         )
        app.logger.info(f"éŸ³é¢‘æå–å®Œæˆ: {audio_path}")
        return audio_path
    except subprocess.CalledProcessError as e:
        app.logger.error(f"éŸ³é¢‘æå–å¤±è´¥: {e.stderr}")
        return None
    except FileNotFoundError:
        app.logger.error("æœªæ‰¾åˆ°ffmpegï¼Œè¯·ç¡®ä¿ffmpegå·²å®‰è£…å¹¶æ·»åŠ åˆ°ç³»ç»ŸPATH")
        return None


def speech_to_text(audio_path):
    """ä½¿ç”¨Whisperå°†éŸ³é¢‘è½¬æ¢ä¸ºå¸¦æ—¶é—´æˆ³çš„æ–‡å­—"""
    app.logger.info(f"å¼€å§‹è¯­éŸ³è½¬æ–‡å­—ï¼ˆWhisperï¼‰ï¼ŒéŸ³é¢‘è·¯å¾„: {audio_path}")

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(audio_path):
        app.logger.error(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        return []

    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    file_size = os.path.getsize(audio_path)
    app.logger.info(f"éŸ³é¢‘æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")

    try:
        # åŠ è½½Whisperæ¨¡å‹ï¼ˆæ ¹æ®éœ€æ±‚é€‰æ‹©æ¨¡å‹å¤§å°ï¼Œtiny/base/small/medium/largeï¼‰
        # æ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½åˆ° ~/.cache/whisper
        # ä½¿ç”¨çš„æ˜¯ModelScopeä¸Šä¸‹è½½çš„whisper-large-v3-turboæ¨¡å‹ï¼
        model_size = "turbo"
        app.logger.info(f"åŠ è½½Whisperæ¨¡å‹: {model_size}")

        # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ï¼ˆä¼˜å…ˆGPUï¼Œæ²¡æœ‰åˆ™ç”¨CPUï¼‰
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model = whisper.load_model(model_size, device=device)

        # è¯­éŸ³è¯†åˆ«ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
        app.logger.info("å¼€å§‹Whisperè¯­éŸ³è¯†åˆ«...")
        # å‚æ•°è¯´æ˜ï¼š
        # - language: å¯é€‰ï¼ŒæŒ‡å®šè¯­è¨€ï¼ˆå¦‚"zh"ï¼‰ï¼Œä¸æŒ‡å®šåˆ™è‡ªåŠ¨æ£€æµ‹
        # - word_timestamps: è‹¥ä¸ºTrueï¼Œä¼šè¿”å›æ¯ä¸ªå•è¯çš„æ—¶é—´æˆ³ï¼ˆæ›´ç²¾ç»†ï¼‰
        result = model.transcribe(
            audio_path,
            language="zh",  # é’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–ï¼Œå¯ç§»é™¤è®©æ¨¡å‹è‡ªåŠ¨æ£€æµ‹
            temperature=0.3,
            word_timestamps=False  # è®¾ä¸ºTrueå¯è·å–å•è¯çº§æ—¶é—´æˆ³
        )

        # æ‰“å°åŸå§‹ç»“æœï¼ˆè°ƒè¯•ç”¨ï¼‰
        app.logger.info(f"Whisperè¯†åˆ«å®Œæˆï¼ŒåŸå§‹ç»“æœ: {json.dumps(result, ensure_ascii=False, indent=2)}")

        # æå–å¸¦æ—¶é—´æˆ³çš„ç‰‡æ®µï¼ˆæ®µè½çº§ï¼‰
        segments = []
        for segment in result.get("segments", []):
            segments.append({
                "start_time": segment["start"],  # å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
                "end_time": segment["end"],  # ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
                "text": segment["text"].strip()  # è¯†åˆ«æ–‡æœ¬
            })
        text = result.get("text", "")  # ä½¿ç”¨getæ–¹æ³•ï¼Œå¦‚æœtextä¸å­˜åœ¨åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        app.logger.info(f"è¯­éŸ³è½¬æ–‡å­—å®Œæˆï¼Œå…±è¯†åˆ«åˆ° {len(segments)} ä¸ªç‰‡æ®µ")
        return segments,text

    except Exception as e:
        app.logger.error(f"Whisperè¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}", exc_info=True)
        return []

def correct_text(text,segments):
    """æ ¹æ®PPTå†…å®¹çº æ­£å­—å¹•æ–‡æœ¬ä¸­çš„æ ‡ç‚¹ç¬¦å·å’Œä¸­è‹±æ–‡è¯†åˆ«é”™è¯¯"""
    try:
        # æ„å»ºæ¶ˆæ¯å†…å®¹ï¼Œç¡®ä¿åŒ…å«"json"å­—æ ·
        messages = [
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­—å¹•æ–‡æ¡ˆç†è§£çº é”™å‘˜ï¼Œè¯·çº æ­£å­—å¹•æ–‡æœ¬ä¸­çš„æ ‡ç‚¹ç¬¦å·å’Œä¸­è‹±æ–‡è¯†åˆ«é”™è¯¯ï¼Œå¹¶æŒ‰ç…§è¯­ä¹‰åˆ’åˆ†æ®µè½ä»¥ä¾¿åç»­çš„åˆ†æ®µæ€»ç»“ã€‚
ç‰¹åˆ«æ³¨æ„ï¼š
1. ä¸“æœ‰åè¯çš„å‡†ç¡®æ€§
2. ä¸“ä¸šæœ¯è¯­çš„æ­£ç¡®æ€§
3. åˆç†åœ°åˆ’åˆ†æ®µè½
4.æ—¶é—´æˆ³æ–‡æœ¬å†…çš„æ¯å¥è¯ä¹Ÿè¦åŒæ­¥æŒ‰è¦æ±‚åšä¿®æ”¹ï¼Œå°¤å…¶æ˜¯æ ‡ç‚¹ç¬¦å·
è¯·ä»¥JSONæ ¼å¼è¿”å›çº æ­£ç»“æœã€‚"""
            },
            {
                "role": "user",
                "content": f"""è¯·ç»“åˆè¦æ±‚å’Œå†…å®¹ï¼Œçº æ­£å­—å¹•æ–‡æœ¬ä¸­çš„é”™è¯¯ï¼š
å­—å¹•æ–‡æœ¬ï¼š
{text},
æ—¶é—´æˆ³æ–‡æœ¬ï¼š
{segments}
è¯·ä»¥JSONæ ¼å¼è¿”å›çº æ­£åçš„æ–‡æœ¬ï¼Œæ ¼å¼ä¸ºï¼š
{{"corrected_text": "çº æ­£åçš„æ–‡æœ¬"}}
{{"segments": "çº æ­£åçš„æ—¶é—´æˆ³æ–‡æœ¬"}}"""
            }
        ]

        # è°ƒç”¨APIè·å–çº é”™ç»“æœ
        completion = client.chat.completions.create(
            model="qwen-plus",
            messages=messages,
            stream=False,
            response_format={"type": "json_object"}
        )

        # è§£æè¿”å›çš„JSONå¯¹è±¡
        result = json.loads(completion.choices[0].message.content)

        # æå–çº æ­£åçš„æ–‡æœ¬å’Œæ—¶é—´æˆ³
        corrected_text = result.get("corrected_text", "")
        segments = result.get("segments", segments)  # å¦‚æœæ²¡æœ‰è¿”å›segmentsï¼Œåˆ™ä½¿ç”¨åŸå§‹segments

        return corrected_text, segments
    except Exception as e:
        print(f"çº æ­£å­—å¹•æ–‡æœ¬å¤±è´¥: {str(e)}")
        return {
            "corrected_text": "æ— æ³•çº æ­£å­—å¹•æ–‡æœ¬",
            "error": str(e)
        }

def split_video_to_frames(video_path, fps, video_id):
    """ä½¿ç”¨ffmpegæŒ‰FPSæˆªå¸§"""
    app.logger.info(f"å¼€å§‹åˆ‡åˆ†è§†é¢‘ï¼Œå¸§ç‡: {fps} fps...")

    frames_dir = os.path.join(app.config['FRAMES_FOLDER'], video_id)
    os.makedirs(frames_dir, exist_ok=True)

    cmd = [
        'ffmpeg', '-i', video_path, '-vf', f'fps={fps}', '-f', 'image2',
        '-c:v', 'png', '-compression_level', '1', '-y',
        os.path.join(frames_dir, '%04d.png')
    ]

    try:
        subprocess.run(cmd, check=True, capture_output=True, text=True,
        encoding='utf-8'  # æ˜¾å¼æŒ‡å®šç¼–ç ä¸º UTF-8
     )
        app.logger.info("è§†é¢‘åˆ‡åˆ†å®Œæˆ!")
        return frames_dir
    except subprocess.CalledProcessError as e:
        app.logger.error(f"è§†é¢‘åˆ‡åˆ†å¤±è´¥: {e.stderr}")
        return None
    except FileNotFoundError:
        app.logger.error("æœªæ‰¾åˆ°ffmpegï¼Œè¯·ç¡®ä¿ffmpegå·²å®‰è£…å¹¶æ·»åŠ åˆ°ç³»ç»ŸPATH")
        return None


def split_video_at_timestamps(video_path, video_id, heavys):
    """
    æŒ‰ç»™å®šæ—¶é—´æˆ³åˆ—è¡¨ç²¾ç¡®æˆªå¸§
    :return: æˆªå›¾ç›®å½•è·¯å¾„ï¼›å¤±è´¥è¿”å› None
    """
    # å‚æ•°æ ¡éªŒ
    if not video_path:
        app.logger.error("video_path ä¸èƒ½ä¸º None æˆ–ç©ºå€¼")
        return None
    if not video_id:
        app.logger.error("video_id ä¸èƒ½ä¸º None æˆ–ç©ºå€¼")
        return None
    if 'FRAMES_FOLDER' not in app.config or not app.config['FRAMES_FOLDER']:
        app.logger.error("FRAMES_FOLDER é…ç½®ä¸å­˜åœ¨æˆ–ä¸ºç©º")
        return None
    if not heavys:
        app.logger.error("heavys åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        return None

    base_dir = os.path.join(app.config['FRAMES_FOLDER'], video_id)
    os.makedirs(base_dir, exist_ok=True)

    # ç»Ÿä¸€å‚æ•°æ¨¡æ¿ï¼ˆæ³¨æ„è¾“å‡ºè·¯å¾„çš„ä½ç½®ï¼‰
    cmd_tpl = [
        'ffmpeg', '-hide_banner', '-loglevel', 'error',
        '-ss', '{time}',  # è¾“å…¥å‰ seekï¼Œç²¾åº¦é«˜
        '-i', video_path,
        '-vframes', '1',  # åªå–ä¸€å¸§
        '-f', 'image2',
        '-c:v', 'png',
        '-y',  # è¦†ç›–
        None  # è¾“å‡ºè·¯å¾„ï¼Œå¾ªç¯é‡Œå¡«ï¼ˆæœ€åä¸€ä¸ªå…ƒç´ ï¼‰
    ]

    for idx, heavy in enumerate(heavys, start=1):
        # æ£€æŸ¥æ—¶é—´èŒƒå›´æ•°æ®æ˜¯å¦å®Œæ•´
        if 'time_range' not in heavy:
            app.logger.error(f"ç¬¬ {idx} ä¸ªheavyç¼ºå°‘time_rangeå­—æ®µ")
            return None
        time_range = heavy['time_range']
        if 'start_time' not in time_range:
            app.logger.error(f"ç¬¬ {idx} ä¸ªheavyç¼ºå°‘start_timeå­—æ®µ")
            return None

        timestamp = time_range['start_time']
        # éªŒè¯æ—¶é—´æˆ³æ ¼å¼ï¼ˆç®€å•æ£€æŸ¥æ˜¯å¦ä¸ºHH:MM:SSæ ¼å¼ï¼‰
        if not re.match(r'^\d{2}:\d{2}:\d{2}$', timestamp):
            app.logger.error(f"ç¬¬ {idx} ä¸ªæ—¶é—´æˆ³æ ¼å¼é”™è¯¯: {timestamp}ï¼Œåº”ä¸ºHH:MM:SS")
            return None

        outfile = os.path.join(base_dir, f'heavy{idx}.png')

        # å¤åˆ¶å‘½ä»¤æ¨¡æ¿å¹¶æ›¿æ¢å‚æ•°ï¼ˆå…³é”®ä¿®æ­£ï¼šä¿®æ”¹æœ€åä¸€ä¸ªå…ƒç´ ä¸ºè¾“å‡ºè·¯å¾„ï¼‰
        cmd = cmd_tpl.copy()
        cmd[-1] = outfile  # ä¿®æ­£è¿™é‡Œï¼è¾“å‡ºè·¯å¾„æ˜¯æœ€åä¸€ä¸ªå‚æ•°
        cmd[4] = timestamp  # ç›´æ¥ä½¿ç”¨HH:MM:SSæ ¼å¼ï¼Œæ— éœ€è½¬str

        try:
            # æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(
                cmd,
                check=True,
                capture_output=True,
                text=True
            )
            app.logger.info(f'å·²æˆªå›¾: {outfile}  (t={timestamp})')
        except subprocess.CalledProcessError as e:
            app.logger.error(f'æˆªå›¾å¤±è´¥ t={timestamp}: {e.stderr}')
            return None
        except FileNotFoundError:
            app.logger.error('æœªæ‰¾åˆ° ffmpegï¼Œè¯·ç¡®ä¿å·²å®‰è£…å¹¶åŠ å…¥ PATH')
            return None

    app.logger.info(f'å…¨éƒ¨æˆªå›¾å®Œæˆï¼Œå…± {len(heavys)} å¼  â†’ {base_dir}')
    return base_dir


def get_sorted_image_files(frames_dir):
    """è·å–æ’åºåçš„å¸§å›¾ç‰‡åˆ—è¡¨"""
    # åªä¼šæ£€æµ‹è¯¥ç›®å½•ä¸‹çš„å›¾ç‰‡ ç”Ÿæˆçš„original_backupæ–‡ä»¶å¤¹ä¸ä¼šæ£€æµ‹åˆ°
    image_files = []
    for ext in ('.jpg', '.jpeg', '.png'):
        image_files.extend(glob.glob(os.path.join(frames_dir, f"*{ext}")))

    filtered_files = []
    for file in image_files:
        try:
            filename = os.path.basename(file)
            num = int(os.path.splitext(filename)[0])
            filtered_files.append((num, file))
        except ValueError:
            continue

    sorted_files = sorted(filtered_files, key=lambda x: x[0])
    return [file for _, file in sorted_files]


def get_captions_for_time_range(speech_segments, start_time, end_time):
    """è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„å­—å¹•"""
    captions = []
    for segment in speech_segments:
        # æ£€æŸ¥è¯­éŸ³ç‰‡æ®µæ˜¯å¦ä¸å½“å‰å¸§æ—¶é—´èŒƒå›´é‡å 
        if not (segment['end_time'] < start_time or segment['start_time'] > end_time):
            captions.append(segment['text'])
    return " ".join(captions) if captions else "æ— è¯­éŸ³å†…å®¹"

def semantic_divide(text,segments):
    try:
        # æ„å»ºæ¶ˆæ¯å†…å®¹ï¼Œç¡®ä¿åŒ…å«"json"å­—æ ·
        messages = [
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡ˆç†è§£åˆ†æ®µå‘˜ï¼Œè¯·æŒ‰ç…§è¯­ä¹‰åˆ’åˆ†æ®µè½æ˜¯ä¸ºäº†åç»­çš„åˆ†æ®µæ€»ç»“ã€‚
    ç‰¹åˆ«æ³¨æ„ï¼š
    1. åˆç†åœ°åˆ’åˆ†æ®µè½ï¼Œæ¯ä¸ªæ®µè½å¯¹åº”ä¸€ä¸ªå°æ ‡é¢˜ï¼Œå¹¶ä¿è¯æ¯ä¸ªæ®µè½ä¸‹æœ‰ä¸‰ä¸ªéå¸¸å…·ä½“çš„å°åˆ†ç‚¹æ€»ç»“
    2.é’ˆå¯¹å­—å¹•æ–‡æœ¬åˆ†æ®µåï¼Œä»æ—¶é—´æˆ³æ–‡æœ¬ä¸­è·å–åˆ†æ®µå¯¹åº”çš„æ—¶é—´ã€‚
    3.æ ¹æ®åˆ†æ®µä»ä¸­æ‰¾å‡ºåˆé€‚çš„é‡ç‚¹å†…å®¹ï¼Œä¹Ÿéœ€è¦è·å¾—æ—¶é—´æˆ³ä¿¡æ¯ã€‚
    4.æ‰€æœ‰æ—¶é—´æˆ³çš„æ ¼å¼å¿…é¡»å¾—æ˜¯hh:mm:ssçš„æ—¶åˆ†ç§’æœ‰:é—´éš”çš„æ ¼å¼,å¹¶ä¸”åˆ†æˆstart_timeå’Œend_timeï¼Œ
    å› ä¸ºæˆ‘è¦å•ç‹¬è·å–è¿™ä¸¤ä¸ªæ•°æ®ï¼
    è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚"""
            },
            {
                "role": "user",
                "content": f"""è¯·ç»“åˆè¦æ±‚å’Œå†…å®¹ï¼Œåˆç†çš„åˆ†æ®µï¼š
    å­—å¹•æ–‡æœ¬ï¼š
    {text},
    æ—¶é—´æˆ³æ–‡æœ¬ï¼š
    {segments}
    è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æ®µæ–‡æœ¬ï¼Œæ ¼å¼ä¸ºï¼š
    {{"division": "åˆ†æ®µçš„å°æ ‡é¢˜title + æ—¶é—´æˆ³å­—ç¬¦ä¸²time_range(åŒ…æ‹¬start_timeå’Œend_time) + ä¸‰ä¸ªå°åˆ†ç‚¹æ€»ç»“summary"}}
    {{"heavys": "é‡ç‚¹çš„å°æ ‡é¢˜title+æ—¶é—´æˆ³å­—ç¬¦ä¸²time_range(åŒ…æ‹¬start_timeå’Œend_time)"}}"""
            }
        ]

        # è°ƒç”¨APIè·å–çº é”™ç»“æœ
        completion = client.chat.completions.create(
            model="qwen-plus",
            messages=messages,
            stream=False,
            response_format={"type": "json_object"}
        )

        # è§£æè¿”å›çš„JSONå¯¹è±¡
        result = json.loads(completion.choices[0].message.content)

        # æå–çº æ­£åçš„æ–‡æœ¬å’Œæ—¶é—´æˆ³
        division = result.get("division", "")
        heavys = result.get("heavys", "")

        return division, heavys
    except Exception as e:
        print(f"åˆ†æ®µè¯­ä¹‰æ–‡æœ¬å¤±è´¥: {str(e)}")



def analyze_frame(text,image_path, captions):
    """ç»“åˆå­—å¹•åˆ†æå¸§å†…å®¹"""
    try:
        # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
        with open(image_path, "rb") as img_file:
            base64_image = base64.b64encode(img_file.read()).decode("utf-8")

        mime_type = 'image/png' if image_path.endswith('.png') else 'image/jpeg'
        image_url = f"data:{mime_type};base64,{base64_image}"

        # è°ƒç”¨åƒé—®æ¨¡å‹åˆ†æå›¾ç‰‡ï¼ˆç»“åˆè¯­éŸ³å­—å¹•ï¼‰
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image_url", "image_url": {"url": image_url}},
                    {"type": "text", "text": f"""è¯·ç»“åˆè¯­éŸ³å†…å®¹è§£æè§†é¢‘ä¸­çš„è¿™ä¸€å¸§ä¼ è¾¾çš„å†…å®¹ï¼š{captions}
                    è¿”å›markdownç¬”è®°çš„JSONæ ¼å¼åŒ…å«ï¼š
                    1. æ ‡é¢˜ï¼šç®€æ´æè¿°ï¼ˆå¤§æ¦‚20å­—ï¼‰
                    2. æ‘˜è¦ï¼šç®€è¦å†…å®¹ï¼ˆå¤§æ¦‚100å­—ï¼‰
                    3. æ‰€æœ‰å†…å®¹è¿”å›markdownçš„ç¬”è®°æ ¼å¼ï¼Œè¦æ±‚ä½¿ç”¨åˆ°ä¸‰ç§çº§åˆ«çš„æ ‡é¢˜ï¼Œå¹¶ä¸”ä¸€èˆ¬åˆ†ä¸‰ç‚¹ç»†èŠ‚è§£è¯´æ‘˜è¦ï¼
                    4.ç¬”è®°ä¸­æ—¢è¦æœ‰ä¸“ä¸šæœ¯è¯­çš„ä½“ç°ï¼Œåˆè¦å¾ªå¾ªå–„è¯±ã€‚
                    5.åœ¨åˆé€‚çš„ä½ç½®å‡ºç°emojiå›¾æ ‡ï¼Œå¢åŠ ç§¯æçš„ä¸°å¯Œæ€§ã€‚
                    6.éœ€è¦æŠŠå›¾ç‰‡ä¸€èµ·åŠ ä¸Šå»ï¼Œå½¢æˆå›¾æ–‡æ··æ’çš„ç¬”è®°æ ¼å¼ã€‚
                    ä»…è¿”å›markdownç¬”è®°ï¼Œåç§°ä¸ºnotesï¼Œæ˜¯JSONæ ¼å¼ã€‚"""
                     }
                ]
            }
        ]

        completion = client.chat.completions.create(
            model="qwen-vl-plus",
            messages=messages,
            stream=False,
            response_format={"type": "json_object"}
        )

        return json.loads(completion.choices[0].message.content)

    except Exception as e:
        app.logger.error(f"å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}")
        return {
            "æ ‡é¢˜": "åˆ†æå¤±è´¥",
            "æ‘˜è¦": "æ— æ³•è§£æå›¾ç‰‡å†…å®¹",
            "äº®ç‚¹": ["åˆ†æé”™è¯¯"],
            "è¯¦ç»†å†…å®¹": f"å›¾ç‰‡åˆ†æé”™è¯¯: {str(e)}"
        }

def generate_mind_map(text):
    """åŸºäºè§†é¢‘å…¨æ–‡å­—å¹•ç”Ÿæˆå‰ç«¯å¯æ¸²æŸ“çš„AIè„‘å›¾"""
    try:
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": f"""åŸºäºè§†é¢‘å…¨æ–‡å­—å¹•ç”Ÿæˆå‰ç«¯å¯ç›´æ¥æ¸²æŸ“çš„AIè„‘å›¾ï¼Œéœ€ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼å’Œè¦æ±‚ï¼š
1. æ ¸å¿ƒç›®æ ‡ï¼šè¾“å‡ºç»“æ„åŒ…å«ã€Œè„‘å›¾åŸºç¡€é…ç½®ã€å’Œã€Œå±‚çº§æ•°æ®ã€ï¼Œæ”¯æŒå‰ç«¯å¿«é€Ÿæ¸²æŸ“ï¼ˆå¦‚vue-mindmapã€mind-elixirç­‰åº“ï¼‰ã€‚
2. è¾“å‡ºæ ¼å¼è§„èŒƒï¼š
   {{
     "mind_map": 
     {{
       "config": {{  // å‰ç«¯æ¸²æŸ“åŸºç¡€é…ç½®ï¼ˆç›´æ¥ç”¨äºè„‘å›¾ç»„ä»¶å‚æ•°ï¼‰
         "root_name": "è§†é¢‘æ ¸å¿ƒä¸»é¢˜ï¼ˆ1çº§èŠ‚ç‚¹ï¼‰",  // æ ¹èŠ‚ç‚¹åç§°ï¼ˆâ‰¤15å­—ï¼Œå¸¦emojiï¼‰
         "theme": "light",  // ä¸»é¢˜æ ‡è¯†ï¼ˆå›ºå®šå€¼ï¼šlight/darkï¼Œæ–¹ä¾¿å‰ç«¯åˆ‡æ¢æ ·å¼ï¼‰
         "default_icon": "ğŸ“Œ",  // é»˜è®¤èŠ‚ç‚¹å›¾æ ‡ï¼ˆé€‚é…ä¸åŒç±»å‹èŠ‚ç‚¹ï¼‰
         "level_styles": {{  // å„å±‚çº§æ ·å¼é…ç½®ï¼ˆå‰ç«¯å¯ç›´æ¥æ˜ å°„CSSï¼‰
           "1": {{ "font_size": "18px", "font_weight": "bold", "color": "#2563eb" }},
           "2": {{ "font_size": "16px", "font_weight": "bold", "color": "#10b981" }},
           "3": {{ "font_size": "14px", "font_weight": "normal", "color": "#6b7280" }},
           "4": {{ "font_size": "12px", "font_weight": "normal", "color": "#9ca3af" }}
         }}
       }},
       "data": {{  // å±‚çº§æ•°æ®ï¼ˆåµŒå¥—ç»“æ„ï¼Œå‰ç«¯å¯ç›´æ¥éå†æ¸²æŸ“ï¼‰
         "id": "root",  // æ ¹èŠ‚ç‚¹IDï¼ˆå›ºå®šä¸ºrootï¼‰
         "name": "ğŸ“Œè§†é¢‘æ ¸å¿ƒä¸»é¢˜ï¼ˆ1çº§èŠ‚ç‚¹ï¼‰",  // åŒconfig.root_nameï¼Œå¸¦emoji
         "level": 1,  // å±‚çº§æ ‡è¯†ï¼ˆ1-4çº§ï¼‰
         "children": [  // å­èŠ‚ç‚¹åˆ—è¡¨ï¼ˆæ¯ä¸ªå­èŠ‚ç‚¹ç»“æ„ä¸çˆ¶èŠ‚ç‚¹ä¸€è‡´ï¼‰
           {{
             "id": "level2_1",  // å”¯ä¸€IDï¼ˆæ ¼å¼ï¼šlevel+å±‚çº§_åºå·ï¼Œå¦‚level2_1ï¼‰
             "name": "ğŸ”§äºŒçº§åˆ†ç±»1ï¼ˆå¦‚ï¼šæ¦‚å¿µè§£æï¼‰",  // â‰¤20å­—ï¼Œå¸¦emoji
             "level": 2,
             "children": [
               {{
                 "id": "level3_1_1",
                 "name": "ğŸ“ä¸‰çº§è¦ç‚¹1ï¼ˆå¦‚ï¼šæ ¸å¿ƒæœ¯è¯­å®šä¹‰ï¼‰",  // â‰¤25å­—ï¼Œå¸¦emoji
                 "level": 3,
                 "children": [
                   {{
                     "id": "level4_1_1_1",
                     "name": "å››çº§è¡¥å……ï¼šæœ¯è¯­é€šä¿—è§£é‡Šï¼ˆè´´åˆå­—å¹•å†…å®¹ï¼Œâ‰¤50å­—ï¼‰",  // å¸¦ç»†èŠ‚è¯´æ˜
                     "level": 4,
                     "children": []  // å››çº§èŠ‚ç‚¹æ— å­é›†ï¼ˆå›ºå®šä¸ºç©ºæ•°ç»„ï¼‰
                   }}
                   // æ›´å¤šå››çº§èŠ‚ç‚¹...
                 ]
               }}
               // æ›´å¤šä¸‰çº§èŠ‚ç‚¹...
             ]
           }}
           // æ›´å¤šäºŒçº§èŠ‚ç‚¹...
         ]
       }}
     }}
   }}
3. å†…å®¹è¦æ±‚ï¼š
   - æ•°æ®ä¸¥æ ¼è´´åˆè§†é¢‘å…¨æ–‡å­—å¹•ï¼Œä¸æ·»åŠ ä¸»è§‚ä¿¡æ¯ï¼›
   - æ¯ä¸ªèŠ‚ç‚¹IDå”¯ä¸€ï¼ˆæ ¼å¼ï¼šlevel+å±‚çº§_åºå·ï¼Œå¦‚level2_2è¡¨ç¤ºäºŒçº§åˆ†ç±»ç¬¬2ä¸ªï¼‰ï¼›
   - 1-4çº§èŠ‚ç‚¹å¿…é¡»å®Œæ•´ï¼Œè¦†ç›–å­—å¹•ä¸­çš„æ ¸å¿ƒæ¦‚å¿µã€æµç¨‹ã€æ¡ˆä¾‹ã€ç»“è®ºï¼›
   - ä¸“ä¸šæœ¯è¯­éœ€åœ¨å››çº§èŠ‚ç‚¹è¡¥å……é€šä¿—è§£é‡Šï¼ˆå¦‚ï¼šã€ŒAPIæ¥å£â†’åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼Œç”¨äºè½¯ä»¶é—´æ•°æ®äº¤äº’ã€ï¼‰ã€‚
4. è¾“å‡ºé™åˆ¶ï¼šä»…è¿”å›ä¸Šè¿°JSONç»“æ„ï¼Œä¸åŒ…å«ä»»ä½•é¢å¤–æ–‡å­—ï¼Œç¡®ä¿å‰ç«¯å¯ç›´æ¥ç”¨JSON.parseè§£æã€‚

è§†é¢‘å…¨æ–‡å­—å¹•å†…å®¹ï¼š{text}
"""}
                ]
            }
        ]

        completion = client.chat.completions.create(
            model="qwen-vl-plus",
            messages=messages,
            stream=False,
            response_format={"type": "json_object"}
        )

        return json.loads(completion.choices[0].message.content)

    except Exception as e:
        app.logger.error(f"AIè„‘å›¾ç”Ÿæˆå¤±è´¥: {str(e)}")
        # é”™è¯¯æ—¶è¿”å›å…¼å®¹æ ¼å¼ï¼Œå‰ç«¯å¯æ•è·å¹¶æ˜¾ç¤ºé”™è¯¯
        return {
            "mind_map": {
                "config": {
                    "root_name": "ğŸ“Œè„‘å›¾ç”Ÿæˆå¤±è´¥",
                    "theme": "light",
                    "default_icon": "âŒ",
                    "level_styles": {
                        "1": {"font_size": "18px", "font_weight": "bold", "color": "#ef4444"}
                    }
                },
                "data": {
                    "id": "root",
                    "name": "ğŸ“Œè„‘å›¾ç”Ÿæˆå¤±è´¥",
                    "level": 1,
                    "children": [
                        {
                            "id": "error_1",
                            "name": f"âŒé”™è¯¯åŸå› ï¼š{str(e)}",
                            "level": 2,
                            "children": []
                        }
                    ]
                }
            }
        }

def generate_summary(text):
    """ç”Ÿæˆå…¨æ–‡æ‘˜è¦å’Œäº®ç‚¹"""
    try:
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æä¸“å®¶ï¼Œæ ¹æ®æ–‡æœ¬å†…å®¹ç”Ÿæˆå¯¹è§†é¢‘çš„æ•´ä½“æ‘˜è¦å’Œäº®ç‚¹ã€‚"
            },
            {
                "role": "user",
                "content": f"""æ ¹æ®æ–‡æœ¬ç”Ÿæˆå†…å®¹ï¼š
                1. æ•´ä½“æ‘˜è¦ï¼ˆ300å­—å·¦å³ï¼‰ï¼ŒæŒ‰ç…§â€œè¯¥è§†é¢‘ä¸»è¦è®²è¿°äº†... é¦–å…ˆ...ç„¶å...æ¥ç€...æœ€å...â€çš„é¡ºåºæè¿°ã€‚
                3.æ ¹æ®æ–‡æœ¬å†…å®¹æ£€æµ‹å‡º2-5ä¸ªè§†é¢‘çš„äº®ç‚¹å†…å®¹ï¼Œè¿”å›äº®ç‚¹å†…å®¹çš„å°æ ‡é¢˜ï¼ˆ10å­—å·¦å³ï¼‰
                æ–‡æœ¬å†…å®¹ï¼š{text}
                ç”¨JSONè¿”å›ï¼ŒåŒ…å«"summary"å’Œ"highlights"å­—æ®µã€‚"""
            }
        ]

        completion = client.chat.completions.create(
            model="qwen-plus",
            messages=messages,
            stream=False,
            response_format={"type": "json_object"}
        )

        return json.loads(completion.choices[0].message.content)
    except Exception as e:
        app.logger.error(f"ç”Ÿæˆæ‘˜è¦å¤±è´¥: {str(e)}")
        return {
            "summary": "æ— æ³•ç”Ÿæˆè§†é¢‘æ‘˜è¦",
            "highlights": ["ç”Ÿæˆæ‘˜è¦æ—¶å‘ç”Ÿé”™è¯¯"]
        }

#æŠŠgenerate_summaryï¼Œgenerate_mind_mapï¼Œsemantic_divideä¸‰ä¸ªåŸºäºä¿®æ­£å­—å¹•çš„å‡½æ•°ä¿®æ­£
def all3(text, speech_segments):
    """ä½ çš„ä¸»å‡½æ•°ï¼Œå¹¶è¡Œæ‰§è¡Œä¸¤ä¸ªä»»åŠ¡"""
    # å®šä¹‰ç”¨äºå­˜å‚¨å¹¶è¡Œç»“æœçš„å˜é‡ï¼ˆç”¨åˆ—è¡¨/å­—å…¸å­˜å‚¨ï¼Œå› ä¸ºçº¿ç¨‹å†…ä¸èƒ½ç›´æ¥è¿”å›å€¼ï¼‰
    result = {}

    # ä»»åŠ¡1ï¼šæ‰§è¡Œ semantic_divide
    def task_semantic_divide():
        division, heavys = semantic_divide(text, speech_segments)
        result['division'] = division
        result['heavys'] = heavys

    # ä»»åŠ¡2ï¼šæ‰§è¡Œ generate_mind_map
    def task_generate_mind_map():
        mind_map = generate_mind_map(text)
        result['mind_map'] = mind_map

    def task_generate_summary():
        summary_result= generate_summary(text)
        result['summary_result'] = summary_result

    # æ–¹å¼1ï¼šç”¨ ThreadPoolExecutor ç®¡ç†çº¿ç¨‹ï¼ˆæ›´ç®€æ´ï¼Œè‡ªåŠ¨ç®¡ç†çº¿ç¨‹ç”Ÿå‘½å‘¨æœŸï¼‰
    with ThreadPoolExecutor(max_workers=3) as executor:  # æœ€å¤š2ä¸ªçº¿ç¨‹å¹¶è¡Œ
        # æäº¤ä¸‰ä¸ªä»»åŠ¡åˆ°çº¿ç¨‹æ± 
        future1 = executor.submit(task_semantic_divide)
        future2 = executor.submit(task_generate_mind_map)
        future3 = executor.submit(task_generate_summary)

        # ç­‰å¾…ä¸‰ä¸ªä»»åŠ¡éƒ½æ‰§è¡Œå®Œæˆï¼ˆé˜»å¡ï¼Œç›´åˆ°æ‰€æœ‰ä»»åŠ¡ç»“æŸï¼‰
        future1.result()
        future2.result()
        future3.result()

    # å¹¶è¡Œæ‰§è¡Œå®Œæˆåï¼Œä»resultä¸­è·å–ç»“æœ
    division = result['division']
    heavys = result['heavys']
    mind_map = result['mind_map']
    summary_result = result['summary_result']

    return division, heavys, mind_map,summary_result


def generate_error_image(message):
    """ç”Ÿæˆä¸€å¼ åŒ…å«é”™è¯¯ä¿¡æ¯çš„å›¾ç‰‡ï¼ˆæ›¿ä»£JSONé”™è¯¯å“åº”ï¼‰"""
    # åˆ›å»ºä¸€å¼ 200x100çš„ç©ºç™½å›¾ç‰‡
    img = Image.new('RGB', (400, 200), color=(240, 240, 240))
    draw = ImageDraw.Draw(img)

    # å°è¯•åŠ è½½ç³»ç»Ÿå­—ä½“ï¼ˆå¦‚æœæ²¡æœ‰åˆ™ä¸æ˜¾ç¤ºæ–‡å­—ï¼‰
    try:
        font = ImageFont.truetype('arial.ttf', 16)  # Windowsç³»ç»Ÿå­—ä½“
    except:
        try:
            font = ImageFont.truetype('/Library/Fonts/Arial.ttf', 16)  # macOSç³»ç»Ÿå­—ä½“
        except:
            font = None  # æ— å­—ä½“æ—¶ä¸ç»˜åˆ¶æ–‡å­—

    # åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶é”™è¯¯ä¿¡æ¯
    if font:
        draw.text((20, 80), message, fill=(255, 0, 0), font=font)
    else:
        draw.text((20, 80), message, fill=(255, 0, 0))  # æ— å­—ä½“æ—¶ä½¿ç”¨é»˜è®¤æ ·å¼

    # å°†å›¾ç‰‡è½¬ä¸ºå­—èŠ‚æµè¿”å›
    img_byte_arr = io.BytesIO()
    img.save(img_byte_arr, format='PNG')
    img_byte_arr.seek(0)

    # è¿”å›å›¾ç‰‡å“åº”ï¼ˆæŒ‡å®šMIMEç±»å‹ï¼‰
    from flask import make_response
    response = make_response(img_byte_arr.getvalue())
    response.headers['Content-Type'] = 'image/png'
    return response

@app.route('/upload', methods=['POST'])
def upload_file():
    """å¤„ç†è§†é¢‘ä¸Šä¼ """
    if 'video' not in request.files:
        return jsonify({"success": False, "error": "æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶"})

    file = request.files['video']
    if file.filename == '':
        return jsonify({"success": False, "error": "æœªé€‰æ‹©è§†é¢‘æ–‡ä»¶"})

    if file and allowed_file(file.filename):
        video_id = str(uuid.uuid4())
        file_ext = file.filename.rsplit('.', 1)[1].lower() if '.' in file.filename else 'mp4'
        filename = f"{video_id}.{file_ext}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)

        return jsonify({
            "success": True,
            "filepath": filename,
            "video_id": video_id
        })

    return jsonify({"success": False, "error": "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"})


@app.route('/analyze', methods=['POST'])
def analyze_video():
    """åˆ†æè§†é¢‘ï¼ˆæˆªå¸§+è¯­éŸ³è¯†åˆ«+å¸§åˆ†æ+ç”Ÿæˆæ‘˜è¦ï¼‰"""
    data = request.get_json()
    if not data or 'filepath' not in data:
        return jsonify({"success": False, "error": "ç¼ºå°‘è§†é¢‘è·¯å¾„å‚æ•°"})

    video_path = os.path.join(app.config['UPLOAD_FOLDER'], data['filepath'])
    video_id = data.get('video_id', str(uuid.uuid4()))
    if not os.path.exists(video_path):
        return jsonify({"success": False, "error": "è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨"})

    try:
        # 1. è·å–è§†é¢‘æ—¶é•¿
        duration = get_video_duration(video_path)
        app.logger.info(f"è§†é¢‘æ—¶é•¿: {duration:.2f}ç§’")

        # 2. æå–éŸ³é¢‘å¹¶è½¬æ–‡å­—
        audio_path = extract_audio_from_video(video_path, video_id)
        speech_segments,text = speech_to_text(audio_path) if audio_path else ([], "")
        text,speech_segments=correct_text(text,speech_segments);
        # æˆ‘æŠŠä¸‰ä¸ªå‡½æ•°å¹¶å‘æ‰§è¡Œäº†
        division,heavys,mind_map,summary_result=all3(text, speech_segments);
        # è·å–heavyså¯¹åº”æ—¶é—´æˆ³çš„ç”»é¢

        # 3. åŠ¨æ€è®¾ç½®å¸§ç‡ï¼ˆç¡®ä¿åˆç†çš„æˆªå¸§æ•°é‡ï¼‰
        if duration < 60:  # <1åˆ†é’Ÿ
            fps = 1/6  # 1ç§’1å¸§
        elif duration < 300:  # <5åˆ†é’Ÿ
            fps = 0.5  # 2ç§’1å¸§
        else:  # â‰¥5åˆ†é’Ÿ
            fps = 0.2  # 5ç§’1å¸§
        app.logger.info(f"é€‰æ‹©å¸§ç‡: {fps} fpsï¼ˆé¢„è®¡ç”Ÿæˆ {int(duration * fps)} å¸§ï¼‰")

        heavys_dir=split_video_at_timestamps(video_path,video_id,heavys);
        # 4. æˆªå¸§å¤„ç†
        frames_dir = split_video_to_frames(video_path, fps, video_id)
        if not frames_dir:
            return jsonify({"success": False, "error": "è§†é¢‘åˆ‡åˆ†å¤±è´¥"})
        # åœ¨è¿™é‡Œå¯¹æŠ½å¸§çš„å›¾ç‰‡åšç›¸ä¼¼åº¦çš„å¤„ç† ç”ŸæˆPPT
        generate_ppt(frames_dir,threshold_input=0.95)
        time.sleep(1)  # ç­‰å¾…æ–‡ä»¶å†™å…¥

        sorted_images = get_sorted_image_files(frames_dir)
        if not sorted_images:
            return jsonify({"success": False, "error": "æœªæ‰¾åˆ°å¸§å›¾ç‰‡"})

        # 5. åˆ†ææ¯å¸§å¹¶åŒ¹é…å­—å¹•
        segments = []
        prev_end_time=0
        for i,image_path in enumerate(tqdm(sorted_images, desc="å¤„ç†è¿›åº¦")):
            # è®¡ç®—å½“å‰å¸§çš„åç§°æ¥è®¡ç®—æ—¶é—´èŒƒå›´ æ ¹æ®pptæ¥è¿›è¡Œåˆ’åˆ†
            basename=os.path.basename(image_path)
            frame_name=basename[:4]
            i=int(frame_name)
            frame_start_time = prev_end_time
            frame_end_time = i  / fps
            prev_end_time=frame_end_time
            time_range = f"{timedelta(seconds=int(frame_start_time))} - {timedelta(seconds=int(frame_end_time))}"

            # è·å–è¯¥æ—¶é—´èŒƒå›´å†…çš„å­—å¹•
            frame_captions = get_captions_for_time_range(speech_segments, frame_start_time, frame_end_time)

            # åˆ†æå¸§å†…å®¹ï¼ˆç»“åˆå­—å¹•ï¼‰
            frame_analysis = analyze_frame(text,image_path, frame_captions)

            BASE_URL = 'http://localhost:5000'
            # æ„å»ºåˆ†æ®µä¿¡æ¯
            segments.append({
                "notes": frame_analysis["notes"],
                "image": BASE_URL+ f"/frames/{video_id}/{os.path.basename(image_path)}",
                "time_range": time_range,
                "captions": frame_captions  # å¯¹åº”æ—¶é—´çš„å­—å¹•
            })
            time.sleep(1)  # æ§åˆ¶APIè°ƒç”¨é¢‘ç‡

        # 7. ä¿å­˜ç»“æœå¹¶è¿”å›
        result = {
            "summary": summary_result["summary"],
            "highlights": summary_result["highlights"],
            "segments": segments,
            "division":division,
            "heavys":heavys,
            "mind_map":mind_map
        }

        result_path = os.path.join(app.config['OUTPUT_FOLDER'], f"{video_id}_result.json")
        with open(result_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        return jsonify({"success": True, "result": result,"video_id": video_id})

    except Exception as e:
        app.logger.error(f"è§†é¢‘åˆ†æå¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": f"è§†é¢‘åˆ†æå¤±è´¥: {str(e)}"})


@app.route('/uploads/<path:filename>')
def uploaded_file(filename):
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)

# è¿”å›å›¾ç‰‡åç§°æ•°ç»„çš„è·¯ç”±
@app.route('/frames/<video_id>',methods=['GET'])
def get_PPT(video_id):
    frame_folder=os.path.join(app.config['FRAMES_FOLDER'], video_id)
    ppt=[];
    heavy=[];
    for file in os.listdir(frame_folder):
        if file.endswith('.png') :
            if file.startswith('heavy'):
                heavy.append(f"/frames/{video_id}/{file}")
            else:
                ppt.append(f"/frames/{video_id}/{file}")
    return jsonify({"success": True, "ppt": ppt,"heavy":heavy})

# éœ€è¦æ·»åŠ ä¸‹é¢çš„è·¯ç”± å•ä¸ªå›¾ç‰‡æ‰å¯ä»¥è®¿é—®åˆ°ï¼
# æ–°å¢ï¼šç”¨äºç›´æ¥è®¿é—®å›¾ç‰‡æ–‡ä»¶çš„è·¯ç”±
@app.route('/frames/<video_id>/<filename>', methods=['GET'])
def get_frame_image(video_id, filename):
    # æ‹¼æ¥å›¾ç‰‡æ‰€åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„
    frame_folder = os.path.join(app.config['FRAMES_FOLDER'], video_id)

    # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æ˜¯PNGæ ¼å¼
    if not os.path.exists(frame_folder):
        return jsonify({"success": False, "error": "è§†é¢‘å¸§æ–‡ä»¶å¤¹ä¸å­˜åœ¨"}), 404

    if not filename.endswith('.png'):
        return jsonify({"success": False, "error": "åªæ”¯æŒPNGæ ¼å¼å›¾ç‰‡"}), 400

    # æ˜¾ç¤ºMIMEçš„å‘Šè¯‰å‰ç«¯æ˜¯å›¾ç‰‡
    try:
        return send_from_directory(frame_folder, filename,mimetype='image/png')
    except FileNotFoundError:
        return generate_error_image("å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨"),404

if __name__ == '__main__':
    # # è‡ªåŠ¨å®‰è£…ä¾èµ–
    # required_packages = ['flask-cors', 'tqdm', 'openai', 'baidu-aip', 'chardet']
    # for package in required_packages:
    #     try:
    #         __import__(package)
    #     except ImportError:
    #         subprocess.run(["pip", "install", package])

    app.run(host='0.0.0.0', port=5000, debug=True)